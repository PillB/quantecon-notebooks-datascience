{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "> **Co-authors**\n",
    "- [Quentin Batista *University of Tokyo*](https://github.com/QBatista)\n",
    "- [Thomas Sargent *NYU*](http://www.tomsargent.com/)\n",
    "- [Paul Schrimpf *UBC*](https://economics.ubc.ca/faculty-and-staff/paul-schrimpf/)\n",
    "- [Natasha Watkins *UCLA*](https://github.com/natashawatkins)\n",
    "\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- [Regression](regression.ipynb)  \n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand what problems classification solves  \n",
    "- Evaluate classification models using a variety of metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Classification](#Classification)  \n",
    "  - [Introduction to Classification](#Introduction-to-Classification)  \n",
    "  - [Warmup Example: Logistic Regression](#Warmup-Example:-Logistic-Regression)  \n",
    "  - [Model Evaluation](#Model-Evaluation)  \n",
    "  - [Neural Network Classifiers](#Neural-Network-Classifiers)  \n",
    "  - [Application: predicting US recessions](#Application:-predicting-US-recessions)  \n",
    "  - [Exercises](#Exercises)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Uncomment following line to install on colab\n",
    "#! pip install qeds fiona geopandas xgboost gensim folium pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Classification\n",
    "\n",
    "We now move from regression to the second main branch of machine learning:\n",
    "classification\n",
    "\n",
    "Recall that the regression problem was to construct a mapping from a set of\n",
    "feature variable to a continuous target\n",
    "\n",
    "Classification is similar to regression, but instead of predicting a continuous\n",
    "target, classification algorithms attempt to apply one (or more) of a discrete\n",
    "number of labels or classes to each observation\n",
    "\n",
    "Another way to put it is that for regression the targets are usually\n",
    "continuous-valued, while in classification the targets are categorical\n",
    "\n",
    "Common examples of classification problems are\n",
    "\n",
    "- Labeling emails as spam or not  \n",
    "- Person identification in a photo  \n",
    "- Speech recognition  \n",
    "- Whether or not a country is or will be in a recession  \n",
    "\n",
    "\n",
    "Classification can also be applied in settings where the target isn’t naturally\n",
    "categorical\n",
    "\n",
    "For example, suppose we want to predict if the unemployment rate for a state\n",
    "will be low ($ <3\\% $), medium ($ \\in [3\\%, 5\\%] $), or high ($ >5\\% $)\n",
    "but don’t necessarily care about the actual number\n",
    "\n",
    "While most economic problems are posed in continuous terms, it may take a bit\n",
    "of creativity to determine the optimal way to categorize a target variable so\n",
    "classification algorithms can be applied\n",
    "\n",
    "Just as many problems can be posed either as classification or regression, many\n",
    "machine learning algorithms have variants that perform regression or\n",
    "classification tasks\n",
    "\n",
    "Throughout this lecture we will revisit some of the algorithms from\n",
    "[regression](regression.ipynb) lecture and discuss how they can be applied in\n",
    "classification settings\n",
    "\n",
    "As we have seen relatives of many of these algorithms, this lecture will be\n",
    "lighter on exposition and build up to an application at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model, metrics, neural_network, pipeline, preprocessing, model_selection\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# activate plot theme\n",
    "import qeds\n",
    "qeds.themes.mpl_style();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup Example: Logistic Regression\n",
    "\n",
    "We have actually already come across a classification algorithm\n",
    "\n",
    "In the [recidivism](recidivism.ipynb) example we attempted to predict whether\n",
    "or not an individual would commit another crime using a combination of the\n",
    "assigned COMPAS score and the individual’s gender or race\n",
    "\n",
    "In that example we used a *logistic regression* model, which is a close\n",
    "relative of the linear regression model we saw in the [regression](regression.ipynb) section\n",
    "\n",
    "The logistic regression model for predicting the likelihood of recidivism using\n",
    "the `COMPAS` score as the single feature is written\n",
    "\n",
    "$$\n",
    "p(\\text{recid}) = L(\\beta_0 + \\beta_1 \\text{COMPAS} + \\epsilon)\n",
    "$$\n",
    "\n",
    "where $ L $ is the *logistic function*: $ L(x) = \\frac{1}{1 + e^{-x}} $\n",
    "\n",
    "To get some intuitions for this function, let’s plot it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 100)\n",
    "y = 1/(1+np.exp(-x))\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for all values of $ x $ the value of the logistic function is\n",
    "always between 0 and 1\n",
    "\n",
    "This makes it perfectly suited for binary classification problems that need to\n",
    "output a probability of one of the two labels\n",
    "\n",
    "Let’s load up the recidivism data and fit the Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/propublica/compas-analysis\"\n",
    "data_url += \"/master/compas-scores-two-years.csv\"\n",
    "\n",
    "df = pd.read_csv(data_url)\n",
    "df.head()\n",
    "\n",
    "X = df[[\"decile_score\"]]\n",
    "y = df[\"two_year_recid\"]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "logistic_model = linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "beta_0 = logistic_model.intercept_[0]\n",
    "beta_1 = logistic_model.coef_[0][0]\n",
    "\n",
    "print(f\"Fit model: p(recid) = L({beta_0:.4f} + {beta_1:.4f} decile_score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from these coefficients that an increase in the `decile_score` leads\n",
    "to an increase in the predicted probability of recidivism\n",
    "\n",
    "Suppose we choose to classify any model output greater than 0.5 as at risk of\n",
    "recidivism\n",
    "\n",
    "Then, because of the positive coefficient on `decile_score` there is a\n",
    "threshold level of the COMPAS score above which all individuals will be labeled\n",
    "as high-risk\n",
    "\n",
    "\n",
    "<a id='exercise-0'></a>\n",
    "> See exercise 1 in the [*exercise list*](#exerciselist-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Decision Boundaries\n",
    "\n",
    "With just one feature that has a positive coefficient, the predictions of the\n",
    "model will always have this cutoff structure\n",
    "\n",
    "Let’s add a second feature the model, the age of the individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X = df[[\"decile_score\", \"age\"]]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "logistic_age_model = linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "logistic_age_model.fit(X_train, y_train)\n",
    "\n",
    "beta_0 = logistic_age_model.intercept_[0]\n",
    "beta_1, beta_2 = logistic_age_model.coef_[0]\n",
    "\n",
    "print(f\"Fit model: p(recid) = L({beta_0:.4f} + {beta_1:.4f} decile_score + {beta_2:.4f} age)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we that an increase in the `decile_score` still leads to an increase in\n",
    "the predicted probability of recidivism, while older individuals are slightly\n",
    "less likely to commit crime again\n",
    "\n",
    "We’ll build on an example from the [scikit-learn documentation](https://scikit-learn.org/stable/auto_examples/svm/plot_iris.html) to visualize the predictions of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_contours(ax, mod, xx, yy, **params):\n",
    "    \"\"\"\n",
    "    Plot the decision boundaries for a classifier with 2 features x and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    mod: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = mod.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def fit_and_plot_decision_boundary(mod, X, y, **params):\n",
    "    # fit model\n",
    "    mod.fit(X, y)\n",
    "\n",
    "    # generate grids of first two columns of X\n",
    "    def gen_grid(xseries):\n",
    "        if xseries.nunique() < 50:\n",
    "            return sorted(xseries.unique())\n",
    "        else:\n",
    "            return np.linspace(xseries.min(), xseries.max(), 50)\n",
    "\n",
    "    x1, x2 = np.meshgrid(gen_grid(X.iloc[:, 0]), gen_grid(X.iloc[:, 1]))\n",
    "\n",
    "    # plot contours and scatter\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_contours(ax, mod, x1, x2, **params)\n",
    "    x1_name, x2_name = list(X)[:2]\n",
    "    X.plot.scatter(x=x1_name, y=x2_name, color=y, ax=ax)\n",
    "    ax.set_xlabel(x1_name)\n",
    "    ax.set_ylabel(x2_name)\n",
    "\n",
    "    return ax\n",
    "\n",
    "fit_and_plot_decision_boundary(\n",
    "    linear_model.LogisticRegression(solver=\"lbfgs\"),\n",
    "    X_train, y_train, cmap=plt.cm.Greys\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see clearly the relationships we identified from the\n",
    "coefficients\n",
    "\n",
    "However we do see that the model is not perfect, there are some solid circles\n",
    "in the light section and some light circles in the solid section\n",
    "\n",
    "This is likely due to two things:\n",
    "\n",
    "1. The model inside the logistic function is a linear regression – thus only a\n",
    "  linear combination of the input features can be used for prediction  \n",
    "1. There is no way to draw a straight line (linear) that perfectly separates\n",
    "  the true from false observations  \n",
    "\n",
    "\n",
    "\n",
    "<a id='exercise-1'></a>\n",
    "> See exercise 2 in the [*exercise list*](#exerciselist-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Before we get too far into additional classification algorithms, let’s take a\n",
    "step back and think about how to evaluate the performance of a classification\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Perhaps the most intuitive classification metric is *accuracy*, which is the\n",
    "fraction of correct predictions\n",
    "\n",
    "For a scikit-learn classifier this can be computed using the `score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "train_acc = logistic_age_model.score(X_train, y_train)\n",
    "test_acc = logistic_age_model.score(X_test, y_test)\n",
    "\n",
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we see that the testing accuracy is similar to or higher than the training\n",
    "accuracy (as we do here) that is a signal that the model might be underfitting\n",
    "and we should consider either using a more powerful model or adding additional\n",
    "features to the model\n",
    "\n",
    "In many contexts this would be an appropriate way to evaluate a model, but in\n",
    "other contexts this would be in sufficient\n",
    "\n",
    "For example, suppose we want to use a classification model to predict the\n",
    "likelihood of someone having a rare, but serious health condition\n",
    "\n",
    "If the condition is very rare, say it shows up in 0.01% of the population, then\n",
    "a model that always predicts false would have 99.99% accuracy but the false\n",
    "negatives would have potentially large consequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "In order to capture situations like that, data scientists often use two other\n",
    "very common metrics:\n",
    "\n",
    "- *Precision*: the number of true positives over the number of positive\n",
    "  predictions. Precision tells us how often the model was correct when it\n",
    "  predicted true  \n",
    "- *Recall*: The number of true positives over the number of actual positives.\n",
    "  Recall answers the question, “what fraction of the positives did we get\n",
    "  correct?”  \n",
    "\n",
    "\n",
    "In the classifying probability of rare health condition example, you may prefer\n",
    "a model with high recall (never misses an at risk patient) even if the\n",
    "precision is a bit low (sometimes you have false positives)\n",
    "\n",
    "On the other hand, if your algorithm was trying to filter spam out of an email\n",
    "inbox you may prefer a model with high precision so that when something is\n",
    "classified as spam it is very likely to actually be spam (i.e. non-spam\n",
    "messages don’t get sent to spam folder)\n",
    "\n",
    "In many settings, both precision and recall are equally important and a\n",
    "compound metric, known as the F1-score is used:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "$$\n",
    "\n",
    "The F1 score is bounded between 0 and 1 and will only achieve a value of 1 if\n",
    "both precision and recall are exactly 1\n",
    "\n",
    "We can have scikit-learn produce a textual report with a precision and\n",
    "\n",
    "Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "report = metrics.classification_report(\n",
    "    y_train, logistic_age_model.predict(X_train),\n",
    "    target_names=[\"no recid\", \"recid\"]\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC and AUC\n",
    "\n",
    "For classification algorithms there is a tradeoff between precision and recall\n",
    "\n",
    "Let’s illustrate this point in the context of the logistic regression model\n",
    "\n",
    "The output of a logistic regression is a probability of an event or label\n",
    "\n",
    "In order to get a definite prediction from the algorithm, the modeler would\n",
    "first select a threshold parameter $ p $ such that all model outputs above the\n",
    "threshold are given the label of true\n",
    "\n",
    "As this $ p $ increases the model must be relatively more confident before\n",
    "assigning a label of true\n",
    "\n",
    "In this case the model’s precision will increase (very confident when applying\n",
    "true label), but the recall will suffer (will apply false to some true cases\n",
    "that had a model output just below the raised threshold)\n",
    "\n",
    "Machine learning practitioners have adapted a way to help us visualize\n",
    "this tradeoff\n",
    "\n",
    "The visualization technique is known as the receiver operating characteristic\n",
    "– or more commonly used ROC – curve <sup>[1](#roc)</sup>\n",
    "\n",
    "To understand what this curve is, consider two extremes choices for $ p $:\n",
    "\n",
    "- When $ p=1 $ we will (almost surely) never predict any observation to\n",
    "  have a label 1. In this case the false positive rate will be equal to 0 as\n",
    "  will the true positive rate  \n",
    "- When $ p=0 $ we will predict that all observations always have a label\n",
    "  of 1. The false positive rate and true positive rates will be equal to 1  \n",
    "\n",
    "\n",
    "The *ROC curve* traces out the relationship between the false positive rate (on\n",
    "the x axis) and the true positive rate (on the y axis) as the probability\n",
    "threshold \\$p\\$ is changed\n",
    "\n",
    "Below we define a function that uses scikit-learn to compute the true positive\n",
    "rate and false positive rates for us and then plot these rates against\n",
    "each-other\n",
    "\n",
    "<a id='roc'></a>\n",
    "**[1]** The name receiver operating characteristic comes from the\n",
    "context where ROC curves were first used. ROC curves were\n",
    "first used to describe radar receivers during World War II,\n",
    "where the goal was to classify a noisy radar signal as\n",
    "indicating an aircraft or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def plot_roc(mod, X, y):\n",
    "    # predicted_probs is an N x 2 array, where N is number of observations\n",
    "    # and 2 is number of classes\n",
    "    predicted_probs = mod.predict_proba(X_test)\n",
    "\n",
    "    # keep the second column, for label=1\n",
    "    predicted_prob1 = predicted_probs[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, predicted_prob1)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, 1], [0, 1], \"k--\")\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "\n",
    "plot_roc(logistic_age_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ROC curve to determine the optimal value for the threshold\n",
    "\n",
    "Given that the output of our model for the recidivism application could\n",
    "potentially inform judicial decisions that impact the lives of individuals, we\n",
    "should be careful when considering a threshold value with low false\n",
    "positive rate vs high recall (low false negative rate)\n",
    "\n",
    "We may choose to err on the side of low false negative rate so that when the model\n",
    "predicts recidivism it is likely that recidivism will occur – in other words\n",
    "we would favor a high true positive rate even if the false positive rate is\n",
    "higher\n",
    "\n",
    "\n",
    "<a id='exercise-2'></a>\n",
    "> See exercise 3 in the [*exercise list*](#exerciselist-0)\n",
    "\n",
    "\n",
    "The ROC curve can also be used to do hyper-parameter selection for the model’s\n",
    "parameters\n",
    "\n",
    "To see how, consider a model with an ROC curve that has a single point at (0, 1)\n",
    "– meaning the true positive rate is 1 and false positive rate is zero or\n",
    "that the model has 100% accuracy\n",
    "\n",
    "Notice that if we were to integrate to obtain the area under the ROC curve, we\n",
    "would get a value of 1 for the perfect model\n",
    "\n",
    "The area under any other ROC curve would be less than 1\n",
    "\n",
    "Thus, we could use the area under the curve (abbreviated AUC) as an objective\n",
    "metric in cross-validation\n",
    "\n",
    "Let’s see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "predicted_prob1 = logistic_age_model.predict_proba(X)[:, 1]\n",
    "auc = metrics.roc_auc_score(y, predicted_prob1)\n",
    "print(f\"Initial AUC value is {auc:.4f}\")\n",
    "\n",
    "help(linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='exercise-3'></a>\n",
    "> See exercise 4 in the [*exercise list*](#exerciselist-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifiers\n",
    "\n",
    "The final classifier we will visit today is a neural-network classifier, using\n",
    "the multi-layer perceptron network architecture\n",
    "\n",
    "Recall from the [regression](regression.ipynb) chapter that a multi-layer\n",
    "perceptron is made up of a series of nested linear regressions, separated by\n",
    "non-linear activation functions\n",
    "\n",
    "The number of neurons (size of weight matrices and bias vectors) in each layer\n",
    "are hyperparameters that can be chosen by modeler, but for regression the last\n",
    "layer had to have exactly one neuron which represented the single regression\n",
    "target\n",
    "\n",
    "In order to use the MLP for classification tasks we need to make three adjustments:\n",
    "\n",
    "1. Construct a final layer with $ N $ neurons instead of 1, where $ N $ is the number of classes in the classification task  \n",
    "1. Apply a *softmax* function on the output of the network  \n",
    "1. Use the cross-entropy loss function instead of the MSE to optimize network weights and biases  \n",
    "\n",
    "\n",
    "The softmax function applied to a vector $ x \\in \\mathbb{R}^N $ is computed as\n",
    "\n",
    "$$\n",
    "\\sigma(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}}\n",
    "$$\n",
    "\n",
    "In words, the softmax function is computed by exponentiating all the values,\n",
    "then dividing by the sum of exponentiated values\n",
    "\n",
    "The output of the softmax function is a probability distribution (all\n",
    "non-negative and sum to 1), weighted by the relative value of the input values\n",
    "\n",
    "Finally, the cross entropy loss function for $ M $ observations $ y $, with associated softmax vectors $ z $ is\n",
    "\n",
    "$$\n",
    "-\\frac{1}{M} \\sum_{j=1}^M \\sum_{i=1}^N 1_{y_j = i} log\\left(z_{i,j}\\right)\n",
    "$$\n",
    "\n",
    "where $ 1_{y_j = i} $ is an indicator  variable taking on the value of 1 if\n",
    "the observed class was equal to $ i $ for the $ j $ th observation, 0\n",
    "otherwise\n",
    "\n",
    "All the same tradeoffs we saw when we used the multi-layer perceptron for\n",
    "regression will apply for classification tasks\n",
    "\n",
    "This includes positives like automated-feature enginnering and theoretically unlimited flexibility\n",
    "\n",
    "It also includes potential negatives such as a risk of overfitting, high\n",
    "computational expenses compared to many classification algorithms, lack of\n",
    "interpretability\n",
    "\n",
    "For a more detailed discussion, review the [regression lecture](regression.ipynb)\n",
    "\n",
    "\n",
    "<a id='exercise-4'></a>\n",
    "> See exercise 5 in the [*exercise list*](#exerciselist-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: neural network toolboxes\n",
    "\n",
    "Thus far we have been using the routines in scikit-learn’s `neural_network` package\n",
    "\n",
    "These are great for learning and exploratory analysis like we have been doing,\n",
    "but are rarely used in production or real world settings\n",
    "\n",
    "The two main reasons are that the scikit-learn routines do not leverage modern\n",
    "hardware like GPUs (so performance is likely much slower than it could be) and\n",
    "it only provides an implementation of the most basic of deep neural networks\n",
    "\n",
    "If you were to use neural networks in mission-critical situations you would\n",
    "want to use modern neural network libraries such as Google’s [tensorflow](https://www.tensorflow.org/),\n",
    "Facebook’s [pytorch](https://pytorch.org/), the amazon supported [MXNet](https://mxnet.apache.org/), or\n",
    "[fastai](https://www.fast.ai/)\n",
    "\n",
    "Each of these toolkits has its own relative strengths and weaknesses, but we’ve\n",
    "seen tensorflow and pytorch used the most\n",
    "\n",
    "Thankfully, they all support Python as either the only or the primary point of\n",
    "access, so you will be well-prepared to start using them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: predicting US recessions\n",
    "\n",
    "Let’s apply our new classification algorithm knowledge and try to use\n",
    "[leading indicators](https://www.investopedia.com/terms/l/leadingindicator.asp)\n",
    "to predict recessions in the US economy\n",
    "\n",
    "A leading indicator is a variable that tends to move or change before the rest\n",
    "of the economy\n",
    "\n",
    "Many different leading indicators have been proposed – we’ll use a few of them\n",
    "\n",
    "We won’t go into detail defending the choice of these variables as leading\n",
    "indicators, but will show a plot of each of the variables that will let us\n",
    "visually inspect the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep\n",
    "\n",
    "Let’s first gather the data from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "start = \"1974-01-01\"\n",
    "end = datetime.date.today()\n",
    "\n",
    "def pct_change_on_last_year(df):\n",
    "    \"compute pct_change on previous year, assuming quarterly\"\n",
    "    return (df - df.shift(4))/df.shift(4)\n",
    "\n",
    "def get_indicators_from_fred(start=start, end=end):\n",
    "    \"\"\"\n",
    "    Fetch quarterly data on 6 leading indicators from time period start:end\n",
    "    \"\"\"\n",
    "    # yield curve, unemployment, change in inventory, new private housing permits\n",
    "    yc_unemp_inv_permit = (\n",
    "        web.DataReader([\"T10Y2Y\", \"UNRATE\", \"CBIC1\", \"PERMIT\"], \"fred\", start, end)\n",
    "        .resample(\"QS\")\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    # percent change in housing prices and retail sales\n",
    "    hpi_retail = (\n",
    "        web.DataReader([\"USSTHPI\", \"SLRTTO01USQ661S\"], \"fred\", start, end)\n",
    "        .resample(\"QS\")  # already quarterly, adjusting so index is same\n",
    "        .mean()\n",
    "        .pipe(pct_change_on_last_year)\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    indicators = (\n",
    "        yc_unemp_inv_permit\n",
    "        .join(hpi_retail)\n",
    "        .dropna()\n",
    "        .rename(columns=dict(\n",
    "            USSTHPI=\"pct_change_hpi\",\n",
    "            T10Y2Y=\"yield_curve\",\n",
    "            UNRATE=\"unemp\",\n",
    "            CBIC1=\"inventory\",\n",
    "            SLRTTO01USQ661S=\"retail_sales\",\n",
    "            PERMIT=\"house_permits\"\n",
    "        ))\n",
    "    )\n",
    "\n",
    "    return indicators\n",
    "\n",
    "indicators = get_indicators_from_fred()\n",
    "\n",
    "indicators.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also need data on recessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def get_recession_data():\n",
    "    recession = (\n",
    "        web.DataReader([\"USRECQ\"], \"fred\", start, end)\n",
    "        .rename(columns=dict(USRECQ=\"recession\"))\n",
    "        [\"recession\"]\n",
    "    )\n",
    "\n",
    "    # extract start and end date for each recession\n",
    "    start_dates = recession.loc[recession.diff() > 0].index.tolist()\n",
    "    if recession.iloc[0] > 0:\n",
    "        start_dates = [recession.index[0]] + start_dates\n",
    "\n",
    "    end_dates = recession.loc[recession.diff() < 0].index.tolist()\n",
    "\n",
    "    if len(start_dates) != len(end_dates):\n",
    "        raise ValueError(\"Need to have same number of start/end dates!\")\n",
    "\n",
    "    return recession, start_dates, end_dates\n",
    "\n",
    "recession, start_dates, end_dates = get_recession_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take a look at the data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def add_recession_bands(ax):\n",
    "    for s, e in zip(start_dates, end_dates):\n",
    "        ax.axvspan(s, e, color=\"grey\", alpha=0.2)\n",
    "\n",
    "axs = indicators.plot(subplots=True, figsize=(8, 6), layout=(3, 2), legend=False)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    add_recession_bands(ax)\n",
    "    ax.set_title(list(indicators)[i])\n",
    "\n",
    "fig = axs[0, 0].get_figure()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the variables we have chosen you can see that in periods leading up\n",
    "to a recession (noted by the grey bands in background), the leading indicator\n",
    "has a distinct move\n",
    "\n",
    "\n",
    "<a id='exercise-5'></a>\n",
    "> See exercise 6 in the [*exercise list*](#exerciselist-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many leads?\n",
    "\n",
    "If the variables we have chosen truly are leading indicators, we should be able\n",
    "to use leading values of the variables to predict current or future recessions\n",
    "\n",
    "A natural question is how many leads should we include?\n",
    "\n",
    "Let’s explore that question by looking at many different sets of leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def make_train_data(indicators, rec, nlead=4):\n",
    "    return indicators.join(rec.shift(nlead)).dropna()\n",
    "\n",
    "def fit_for_nlead(ind, rec, nlead, mod):\n",
    "    df = make_train_data(ind, rec, nlead)\n",
    "    X = df.drop([\"recession\"], axis=1).copy()\n",
    "    y = df[\"recession\"].copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y)\n",
    "\n",
    "    mod.fit(X_train, y_train)\n",
    "    cmat = metrics.confusion_matrix(y_test, mod.predict(X_test))\n",
    "    return cmat\n",
    "\n",
    "mod = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    ")\n",
    "\n",
    "cmats = dict()\n",
    "for nlead in range(1, 11):\n",
    "    cmats[nlead] = np.zeros((2, 2))\n",
    "    print(f\"starting for {nlead} leads\")\n",
    "    for rep in range(200):\n",
    "        cmats[nlead] += fit_for_nlead(indicators, recession, nlead, mod)\n",
    "\n",
    "    cmats[nlead] = cmats[nlead] / 200\n",
    "\n",
    "for k, v in cmats.items():\n",
    "    print(f\"\\n\\nThe average confusion matrix for {k} lag(s) was:\\n {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the averaged confusion matrices reported above we see that the model with\n",
    "only one leading period was the most accurate\n",
    "\n",
    "After that was the model with 4 leading quarters\n",
    "\n",
    "Depending on the application, we might favor a model with higher accuracy or\n",
    "one that gives us more time to prepare (the 4 quarter model)\n",
    "\n",
    "One reason why the 1 lead and 4 lead models did better than the models with\n",
    "another number of leads might be because different variables start to move a\n",
    "different number of periods before the recession hits\n",
    "\n",
    "The exercise below asks you to explore this idea\n",
    "\n",
    "\n",
    "<a id='exercise-6'></a>\n",
    "> See exercise 7 in the [*exercise list*](#exerciselist-0)\n",
    "\n",
    "\n",
    "\n",
    "<a id='exercise-7'></a>\n",
    "> See exercise 8 in the [*exercise list*](#exerciselist-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "\n",
    "<a id='exerciselist-0'></a>\n",
    "**Exercise 1**\n",
    "\n",
    "Determine what the level of this cutoff value is. Recall that the COMPAS\n",
    "score takes on integer values between 1 and 10, inclusive.\n",
    "\n",
    "What happens to the cutoff level of the `decile_score` when you change\n",
    "the classification threshold from 0.5 to 0.7? What about 0.3? Remember this\n",
    "idea -- we'll come back to it soon\n",
    "\n",
    "([*back to text*](#exercise-0))\n",
    "\n",
    "**Exercise 2**\n",
    "\n",
    "Experiment with different pairs of features to see which ones show the\n",
    "clearest decision boundaries\n",
    "\n",
    "Use the `fit_and_plot_decision_boundary` function above and feed it\n",
    "different `X` DataFrames\n",
    "\n",
    "([*back to text*](#exercise-1))\n",
    "\n",
    "**Exercise 3**\n",
    "\n",
    "Use the `metrics.roc_curve` function to determine an appropriate value\n",
    "for the probability threshold, while keeping in mind our preference for\n",
    "high precision over high recall\n",
    "\n",
    "The third return value of `metrics.roc_curve` is an array of the\n",
    "probability thresholds (`p`) used to compute each false positive rate and\n",
    "true positive rate\n",
    "\n",
    "To do this problem, you may wish to do the following steps:\n",
    "\n",
    "- Come up with some objective function in terms of the `fpr` and `tpr`  \n",
    "- Evaluate the objective function using the `fpr` and `tpr` variables returned by the `metrics.roc_curve` function  \n",
    "- Use `np.argmin` to find the  *index* of the smallest value of the objective function  \n",
    "- Extract from the probability threshold values array the value at the argmin index  \n",
    "\n",
    "\n",
    "*Hint*: If we cared about both precision and recall equally (we don't here)\n",
    "we might choose as on objective function `(fpr - tpr)**2`. With this\n",
    "objective function we will find the value of the probability threshold\n",
    "that makes the false positive and true positive rates as close to equal as\n",
    "possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([*back to text*](#exercise-2))\n",
    "\n",
    "**Exercise 4**\n",
    "\n",
    "The `LogisticRegression` class with default arguments implements the\n",
    "regression including `l2` regularization (it penalizes coefficient\n",
    "vectors with an l2-norm)\n",
    "\n",
    "The strength of regularization is controlled by a parameter `C` that is\n",
    "passed to the `LogisticRegression` constructor\n",
    "\n",
    "Smaller values of `C` lead to stronger regularization\n",
    "\n",
    "For example `LogisticRegression(C=10)` would have weaker regularization\n",
    "than `LogisticRegression(C=0.5)`\n",
    "\n",
    "Your task here is to use the `model_selection.cross_val_score` method,\n",
    "with the `scoring` argument set to `roc_auc` in order to select an\n",
    "optimal level for the regularization parameter `C`\n",
    "\n",
    "Refer to the example in the recidivism lecture for how\n",
    "to use `model_selection.cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([*back to text*](#exercise-3))\n",
    "\n",
    "**Exercise 5**\n",
    "\n",
    "Use the `neural_network.MLPClassifier` class to use a multi-layer\n",
    "perceptron in our recidivism example\n",
    "\n",
    "Experiment with different inputs such as:\n",
    "\n",
    "- The features to include  \n",
    "- The number of layers and number of neurons in each layer  \n",
    "- The l2 regularization parameter `alpha`  \n",
    "- The solver  \n",
    "\n",
    "\n",
    "See if you can come up with a model that outperforms logistic regression\n",
    "\n",
    "Keep in mind other things like the degree of overfitting and time required\n",
    "to estimate the model parameters. How do these compare to logistic\n",
    "regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([*back to text*](#exercise-4))\n",
    "\n",
    "**Exercise 6**\n",
    "\n",
    "Let's pause here to take a few minutes and digest\n",
    "\n",
    "If the task is to use these leading indicators to predict a recession,\n",
    "would high recall or high precision be more important for our model?\n",
    "\n",
    "Would your answer change if you worked at the federal reserve?\n",
    "\n",
    "What if you worked at a news company such as the Economist or the New York\n",
    "Times?\n",
    "\n",
    "([*back to text*](#exercise-5))\n",
    "\n",
    "**Exercise 7**\n",
    "\n",
    "Extend the logic from the previous example and allow for a different number\n",
    "of leading periods for each variable\n",
    "\n",
    "How would you find the \"optimal\" number of leads for each variable? How\n",
    "could you try to avoid overfitting?\n",
    "\n",
    "Use `make_train_data_varying_leads` function below to construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def make_train_data_varying_leads(indicators, rec, nlead):\n",
    "    \"\"\"\n",
    "    Apply per-indicator leads to each indicator and join with recession data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    indicators: pd.DataFrame\n",
    "        A DataFrame with timestamps on index and leading indicators as columns\n",
    "\n",
    "    rec: pd.Series\n",
    "        A Series indicating if the US economy was in a recession each period\n",
    "\n",
    "    nlead: dict\n",
    "        A dictionary mapping a column name to a positive integer\n",
    "        specifying how many periods to shift each indicator. Any\n",
    "        indicator not given a key in this dictionary will not be\n",
    "        included in the output DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        A DataFrame with the leads applied and merged with the recession\n",
    "        indicator\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "\n",
    "    ```\n",
    "    df = make_train_data_varying_leads(\n",
    "        indicators,\n",
    "        recession,\n",
    "        nlead=dict(yield_curve=3, unemp=4)\n",
    "    )\n",
    "\n",
    "    df.shape[1]  # == 3 (yield_curve, unemp, recession))\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "    cols = []\n",
    "    for col in list(indicators):\n",
    "        if col in nlead:\n",
    "            cols.append(indicators[col].shift(-nlead[col]))\n",
    "\n",
    "    X = pd.concat(cols, axis=1)\n",
    "    return X.join(rec).dropna()\n",
    "\n",
    "# your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([*back to text*](#exercise-6))\n",
    "\n",
    "**Exercise 8**\n",
    "\n",
    "Experiment with different classifiers. Which ones perform better or worse?\n",
    "\n",
    "See how accurate you are able to become for each accuracy metric (accuracy, precision, and recall)\n",
    "\n",
    "([*back to text*](#exercise-7))"
   ]
  }
 ],
 "metadata": {
  "filename": "classification.rst",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Classification"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}