{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage formats\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- [Intro to DataFrames and Series](intro.ipynb)  \n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand that data can be saved in various formats  \n",
    "- Know where to get help on file input and output  \n",
    "- Know when to use csv, xlsx, feather, and sql formats  \n",
    "\n",
    "\n",
    "**Data**\n",
    "\n",
    "- Results for all NFL games between September 1920 to February 2017  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Storage formats](#Storage-formats)  \n",
    "  - [File formats](#File-formats)  \n",
    "  - [Writing DataFrames](#Writing-DataFrames)  \n",
    "  - [Reading files into DataFrames](#Reading-files-into-DataFrames)  \n",
    "  - [Practice](#Practice)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Uncomment following line to install on colab\n",
    "#! pip install qeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File formats\n",
    "\n",
    "Data can be saved in a variety of formats\n",
    "\n",
    "Pandas understands how to write and read DataFrames to and from many of\n",
    "these formats\n",
    "\n",
    "We defer to the [official\n",
    "documentation](https://pandas.pydata.org/pandas-docs/stable/io.html)\n",
    "for a full description of how to interact with all the file formats, but\n",
    "will briefly discuss a few of them here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "\n",
    "**What is it?** stores data as plain text (string) where each row is a\n",
    "line and columns are separated by `,`\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Widely used (you should be familiar with it)  \n",
    "- Plain text file (can open on any computer, “future proof”)  \n",
    "- Can be read from and written to by most data software  \n",
    "\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- Not the most efficient way to store or access  \n",
    "- No formal standard, so there is room for user interpretation on how to\n",
    "  handle edge cases (e.g. what to do about a data field that itself includes\n",
    "  a comma)  \n",
    "\n",
    "\n",
    "**When to use**:\n",
    "\n",
    "- A great default option for most use cases  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlsx\n",
    "\n",
    "**What is it?** Binary file format used as the default when working in\n",
    "Excel\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "- Standard format in many industries  \n",
    "- Easy to share with colleagues that use Excel  \n",
    "\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "- Quite slow to read/write large amounts of data  \n",
    "- Stores both data and *metadata* like styling and display information\n",
    "  and even plots. This metadata is not always portable to other file formats\n",
    "  or programs  \n",
    "\n",
    "\n",
    "**When to use**:\n",
    "\n",
    "- When sharing data with Excel using colleagues  \n",
    "- When you would like special formatting to be applied to the\n",
    "  spreadsheet when it is viewed in Excel  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet\n",
    "\n",
    "**What is it?** Custom binary format designed for efficient reading and\n",
    "writing of data stored in columns\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "- *Very* fast  \n",
    "- Naturally understands all `dtypes` used by pandas, including\n",
    "  multi-index DataFrames  \n",
    "- Very common in “big data” systems like Hadoop or Spark  \n",
    "- Supports various compression algorithms  \n",
    "\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "- Binary storage format that is not human readable  \n",
    "\n",
    "\n",
    "**When to use**:\n",
    "\n",
    "- If you have “not small” amounts (> 100 MB) of unchanging data that\n",
    "  you want to read quickly  \n",
    "- If you want to store data in an size-and-time-efficient way that may\n",
    "  be accessed by external systems  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feather\n",
    "\n",
    "**What is it?** Custom binary format designed for efficient reading and\n",
    "writing of data stored in columns\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "- *Very* fast – even faster than parquet  \n",
    "- Naturally understands all `dtypes` used by pandas  \n",
    "\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "- Can only read and write from Python and a handful of other\n",
    "  programming languages  \n",
    "- New file format (introduced in March ‘16), so most files don’t come\n",
    "  in this format  \n",
    "- Only supports standard pandas index, so you need to `reset_index`\n",
    "  before saving and then `set_index` after loading  \n",
    "\n",
    "\n",
    "**When to use**:\n",
    "\n",
    "- Use as an alternative to Parquet if you need absolute best read and write\n",
    "  speeds for unchanging datasets  \n",
    "- Only use when you will not need to access the data in a programming language\n",
    "  or software outside of Python, R, and Julia  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL\n",
    "\n",
    "**What is it?** SQL is a language used to interact with relational\n",
    "databases… [more info](https://en.wikipedia.org/wiki/SQL)\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "- Well established industry standard for handling data  \n",
    "- Much of the world’s data is in a SQL database somewhere  \n",
    "\n",
    "\n",
    "**Cons**:\n",
    "\n",
    "- Complicated: to have full control you need to learn another language\n",
    "  (SQL)  \n",
    "\n",
    "\n",
    "**When to use**:\n",
    "\n",
    "- When reading from or writing to existing SQL databases.  \n",
    "\n",
    "\n",
    "**NOTE**: We can cover interacting with SQL databases in a dedicated\n",
    "lecture – contact us for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing DataFrames\n",
    "\n",
    "Let’s now talk about saving a DataFrame to a file\n",
    "\n",
    "As a general rule of thumb, if we have a DataFrame `df` and we would\n",
    "like to save to save it as a file of type `FOO`, then we would call\n",
    "the method named `df.to_FOO(...)`\n",
    "\n",
    "We will show you how this can be done and try to highlight some of the\n",
    "items mentioned above as we go forward\n",
    "\n",
    "But, we will not cover all the possible options and features — we feel\n",
    "it is best to learn these as you need them by consulting the appropriate\n",
    "documentation\n",
    "\n",
    "First we need some DataFrames to save, let’s make them now\n",
    "\n",
    "Note that by default `df2` will be approximately 10 MB\n",
    "\n",
    "If you need to change this number for any reason, change the value of\n",
    "the `wanted_mb` variable below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)  # makes sure we get the same random numbers each time\n",
    "df1 = pd.DataFrame(\n",
    "    np.random.randint(0, 100, size=(10, 4)),\n",
    "    columns=[\"a\", \"b\", \"c\", \"d\"]\n",
    ")\n",
    "\n",
    "wanted_mb = 10  # CHANGE THIS LINE\n",
    "nrow = 100000\n",
    "ncol = int(((wanted_mb * 1024**2) / 8) / nrow)\n",
    "df2 = pd.DataFrame(\n",
    "    np.random.rand(nrow, ncol),\n",
    "    columns=[\"x{}\".format(i) for i in range(ncol)]\n",
    ")\n",
    "\n",
    "print(\"df2.shape = \", df2.shape)\n",
    "print(\"df2 is approximately {} MB\".format(df2.memory_usage().sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [df.to_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html)\n",
    "\n",
    "Let’s start with `df.to_csv`\n",
    "\n",
    "Without any additional arguments, the `df.to_csv` function will return\n",
    "a string containing the csv form of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# notice the plain text format -- one row per line, columns separated by `'`\n",
    "print(df1.to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do pass an argument, the first one will be used as the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "df1.to_csv(\"df1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to verify that the file was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.isfile(\"df1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how long it takes to save `df2` to a file (the `%%time` at\n",
    "the top will have Jupyter report the total time to run all the code in\n",
    "the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df2.to_csv(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see below, this isn’t as fastest file format we could choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [df.to_excel](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html)\n",
    "\n",
    "When saving a DataFrame to an Excel workbook, we have the ability to\n",
    "choose both the name of the workbook (file) and the name of the sheet\n",
    "within the file where the DataFrame should be written\n",
    "\n",
    "We do this by passing the workbook name as the first argument and the\n",
    "sheet name as the second argument as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "df1.to_excel(\"df1.xlsx\", \"df1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also gives us the option to write more than one DataFrame to a\n",
    "workbook\n",
    "\n",
    "To do this we need to first construct an instance of `pd.ExcelWriter`\n",
    "and then pass that as the first argument to `df.to_excel`\n",
    "\n",
    "Let’s see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"df1.xlsx\") as writer:\n",
    "    df1.to_excel(writer, \"df1\")\n",
    "    (df1 + 10).to_excel(writer, \"df1 plus 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "with ... as ... :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "syntax used above is an example of a *context manager*\n",
    "\n",
    "We don’t need to understand all the details behind what this means\n",
    "(google it if you are curious)\n",
    "\n",
    "For now just recognize that particular syntax as the way to write\n",
    "multiple sheets to an Excel workbook\n",
    "\n",
    "<p style=\"color:red;\">\n",
    "\n",
    "WARNING\n",
    "\n",
    "</p>\n",
    "\n",
    "Saving `df2` to an excel file takes a very long time\n",
    "\n",
    "For that reason we will just show the code and hard-code in the output\n",
    "we saw one time when we ran the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "```python\n",
    "%%time\n",
    "df2.to_excel(\"df2.xlsx\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "```python\n",
    " Wall time: Wall time: 25.7 s\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [pyarrow.feather.write_feather](https://arrow.apache.org/docs/python/generated/pyarrow.feather.write_feather.html#pyarrow.feather.write_feather)\n",
    "\n",
    "As noted above, the feather file format was developed for very efficient\n",
    "reading and writing between Python and your computer\n",
    "\n",
    "Support for this format is provided by a separate Python package called `pyarrow`\n",
    "\n",
    "This package is not installed by default. To install it, copy/paste the code\n",
    "below into a code cell and execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "```markdown\n",
    "!pip install pyarrow\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters for `pyarrow.feather.write_feather` are the dataframe and the file name\n",
    "\n",
    "Let’s try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import pyarrow.feather\n",
    "pyarrow.feather.write_feather(df1, \"df1.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pyarrow.feather.write_feather(df2, \"df2.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example timing result\n",
    "\n",
    "|format|time|\n",
    "|:---------:|:----------------------:|\n",
    "|csv|2.66 seconds|\n",
    "|xlsx|25.7 seconds|\n",
    "|feather|43 milliseconds|\n",
    "As you can see, saving this DataFrame in the feather format was far\n",
    "faster than either CSV or Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files into DataFrames\n",
    "\n",
    "As with the `df.to_FOO` family of methods, there are similar\n",
    "`pd.read_FOO` functions (note they are in defined pandas, not as\n",
    "methods on a DataFrame)\n",
    "\n",
    "Due to the various things that can be messy or wrong about data stored\n",
    "in files, these methods have many more options\n",
    "\n",
    "These will be explored in more detail in a separate lecture\n",
    "\n",
    "For now we just want to highlight the differences in how to read data\n",
    "from each of the file formats\n",
    "\n",
    "Let’s start by reading in the files we just created and verify that they\n",
    "match the data we started out with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# notice that index was specified in the first (0th -- why?) column of the file\n",
    "df1_csv = pd.read_csv(\"df1.csv\", index_col=0)\n",
    "df1_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "df1_xlsx = pd.read_excel(\"df1.xlsx\", \"df1\", index_col=0)\n",
    "df1_xlsx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# notice feather already knows what the index is\n",
    "df1_feather = pyarrow.feather.read_feather(\"df1.feather\")\n",
    "df1_feather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `pd.read_FOO` family of functions, we can also read files\n",
    "from places on the internet.\n",
    "\n",
    "The saved `df1` DataFrame we have been working with to a file\n",
    "and posted online\n",
    "\n",
    "Below we show an example of using `pd.read_csv` to read this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "df1_url = \"https://storage.googleapis.com/workshop_materials/df1.csv\"\n",
    "df1_web = pd.read_csv(df1_url, index_col=0)\n",
    "df1_web.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "Now it’s your turn…\n",
    "\n",
    "In the cell below, the variable `url` contains a web address to a csv\n",
    "file containing the result of all NFL games from September 1920 to\n",
    "February 2017\n",
    "\n",
    "Your task is to do the following:\n",
    "\n",
    "- Use `pd.read_csv` to read this file into a DataFrame named `nfl`  \n",
    "- Print the shape and column names of `nfl`  \n",
    "- Save the DataFrame to a file named `nfl.xlsx`  \n",
    "- Open the spreadsheet using Excel on your computer  \n",
    "\n",
    "\n",
    "If you finish quickly, do some basic analysis of the data. Try to do\n",
    "something interesting. If you get stuck, here are some suggestions for\n",
    "what to try:\n",
    "\n",
    "- Compute the average total points in each game (note, you will need to\n",
    "  sum two of the columns to get total points)  \n",
    "- Repeat the above calculation, but only for playoff games  \n",
    "- Compute the average score for your favorite team (you’ll need to\n",
    "  consider when they were team1 vs team2)  \n",
    "- Compute the ratio of “upsets” to total games played. An upset is\n",
    "  defined as a team with a lower ELO winning the game  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/fivethirtyeight/nfl-elo-game/\"\n",
    "url = url + \"3488b7d0b46c5f6583679bc40fb3a42d729abd39/data/nfl_games.csv\"\n",
    "\n",
    "# your code here --- create more cells if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "If you want to remove the files we just created so we don’t clutter up\n",
    "your hard drive, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def try_remove(file):\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)\n",
    "\n",
    "for df in [\"df1\", \"df2\"]:\n",
    "    for extension in [\"csv\", \"feather\", \"xlsx\"]:\n",
    "        filename = df + \".\" + extension\n",
    "        try_remove(filename)"
   ]
  }
 ],
 "metadata": {
  "filename": "storage_formats.rst",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Storage formats"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}